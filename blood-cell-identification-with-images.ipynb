{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":29380,"sourceType":"datasetVersion","datasetId":9232}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/george1128/blood-cell-identification-with-images?scriptVersionId=272522325\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-28T15:47:23.05837Z","iopub.execute_input":"2025-10-28T15:47:23.058545Z","iopub.status.idle":"2025-10-28T15:47:24.670728Z","shell.execute_reply.started":"2025-10-28T15:47:23.058528Z","shell.execute_reply":"2025-10-28T15:47:24.669906Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#\"This work is using the 'Blood cell images' to show the reusable code for image automentation and pipieline of deep learning. The dataset is from Paul Mooney. https://www.kaggle.com/datasets/paultimothymooney/blood-cells\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T15:47:29.462456Z","iopub.execute_input":"2025-10-28T15:47:29.462814Z","iopub.status.idle":"2025-10-28T15:47:29.466403Z","shell.execute_reply.started":"2025-10-28T15:47:29.462789Z","shell.execute_reply":"2025-10-28T15:47:29.465735Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#import models\nimport sklearn\nimport itertools\nimport cv2\nimport scipy\nimport os\nimport csv\nimport matplotlib.pyplot as plt\nfrom keras.optimizers import RMSprop\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, MaxPool2D\nfrom keras.layers import Lambda, BatchNormalization\n#import numpy as np # linear algebra\n#import pandas as pd\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T15:47:31.610414Z","iopub.execute_input":"2025-10-28T15:47:31.610877Z","iopub.status.idle":"2025-10-28T15:47:44.634594Z","shell.execute_reply.started":"2025-10-28T15:47:31.610853Z","shell.execute_reply":"2025-10-28T15:47:44.633926Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#reads a blood cell image and its corresponding annotation XML file\ndef annotate_image(image_path, xml_path):\n    image = cv2.imread(image_path)\n    tree = ET.parse(xml_path)\n\n    for elem in tree.iter():\n        if 'object' in elem.tag or 'part' in elem.tag:\n            name, xmin, ymin, xmax, ymax = None, None, None, None, None\n            for attr in list(elem):\n                if 'name' in attr.tag:\n                    name = attr.text\n                if 'bndbox' in attr.tag:\n                    coords = {dim.tag: int(round(float(dim.text))) for dim in list(attr)}\n                    xmin, ymin, xmax, ymax = coords['xmin'], coords['ymin'], coords['xmax'], coords['ymax']\n\n            if name:\n                color = (0, 255, 0) if name[0] == \"R\" else (0, 0, 255) if name[0] == \"W\" else (255, 0, 0)\n                cv2.rectangle(image, (xmin, ymin), (xmax, ymax), color, 1)\n                cv2.putText(image, name, (xmin + 10, ymin + 15),\n                            cv2.FONT_HERSHEY_SIMPLEX, 1e-3 * image.shape[0], color, 1)\n    return image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T15:48:06.460538Z","iopub.execute_input":"2025-10-28T15:48:06.46109Z","iopub.status.idle":"2025-10-28T15:48:06.467913Z","shell.execute_reply.started":"2025-10-28T15:48:06.461068Z","shell.execute_reply":"2025-10-28T15:48:06.467071Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import xml.etree.ElementTree as ET\nimage_path = \"/kaggle/input/blood-cells/dataset-master/dataset-master/JPEGImages/BloodImage_00010.jpg\"\nxml_path = \"/kaggle/input/blood-cells/dataset-master/dataset-master/Annotations/BloodImage_00010.xml\"\nannotated_image = annotate_image(image_path, xml_path)\n\nplt.figure(figsize=(16, 16))\nplt.imshow(annotated_image)\nplt.axis('off')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T15:48:16.28836Z","iopub.execute_input":"2025-10-28T15:48:16.288932Z","iopub.status.idle":"2025-10-28T15:48:17.135678Z","shell.execute_reply.started":"2025-10-28T15:48:16.288907Z","shell.execute_reply":"2025-10-28T15:48:17.134667Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#read the labels\nlabels_path =\"/kaggle/input/blood-cells/dataset2-master/dataset2-master/labels.csv\"\nlabels = pd.read_csv(labels_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T15:48:28.243173Z","iopub.execute_input":"2025-10-28T15:48:28.243889Z","iopub.status.idle":"2025-10-28T15:48:28.262402Z","shell.execute_reply.started":"2025-10-28T15:48:28.243868Z","shell.execute_reply":"2025-10-28T15:48:28.261816Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"labels.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define augment images\nimport albumentations as A\n\naugmenter = A.Compose([\n    A.HorizontalFlip(p=0.5),\n    A.Rotate(limit=15, p=0.5),\n    A.GaussianBlur(blur_limit=3, p=0.3),\n    A.RandomBrightnessContrast(p=0.5),\n    A.Normalize(mean=(0.5,), std=(0.5,))  # Optional for model input\n])\n\ndef augment_image(image):\n    augmented = augmenter(image=image)\n    return augmented['image']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T15:48:36.580878Z","iopub.execute_input":"2025-10-28T15:48:36.581184Z","iopub.status.idle":"2025-10-28T15:48:41.340914Z","shell.execute_reply.started":"2025-10-28T15:48:36.581159Z","shell.execute_reply":"2025-10-28T15:48:41.340104Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#read the images and labele\nfrom tqdm import tqdm\ndef get_images_labels(folder):\n    X=[]\n    y =[]\n    wbc_label_map = {\n    'NEUTROPHIL': 1,\n    'EOSINOPHIL':2,\n    'MONOCYTE': 3,\n    'LYMPHOCYTE': 4\n}\n\n    for wbc_type in os.listdir(folder):\n        if not wbc_type.startswith('.'):\n            label = wbc_label_map.get(wbc_type, 5)\n            for image_filename in tqdm(os.listdir(os.path.join(folder, wbc_type))):\n                image_path = os.path.join(folder, wbc_type, image_filename)\n                img_file = cv2.imread(image_path)\n\n                if img_file is not None:\n                    resized_img = cv2.resize(img_file, (80, 60))  # (width, height)\n                    rgb_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n                    image_aug = augment_image(rgb_img)\n                    X.append(image_aug)\n                    y.append(label)\n    \n    X=np.asarray(X)\n    y=np.asarray(y)\n    return X, y\n        \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T15:48:46.318034Z","iopub.execute_input":"2025-10-28T15:48:46.318616Z","iopub.status.idle":"2025-10-28T15:48:46.324232Z","shell.execute_reply.started":"2025-10-28T15:48:46.318595Z","shell.execute_reply":"2025-10-28T15:48:46.323373Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_folder =\"/kaggle/input/blood-cells/dataset2-master/dataset2-master/images/TRAIN/\"\ntest_folder = \"/kaggle/input/blood-cells/dataset2-master/dataset2-master/images/TEST/\"\nX_train, y_train = get_images_labels(train_folder)\nX_test, y_test = get_images_labels(test_folder)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T15:48:51.868724Z","iopub.execute_input":"2025-10-28T15:48:51.869212Z","iopub.status.idle":"2025-10-28T15:50:12.992092Z","shell.execute_reply.started":"2025-10-28T15:48:51.869187Z","shell.execute_reply":"2025-10-28T15:50:12.991474Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# nornalize the X-Train, X-test for RGB images\nX_train = X_train / 255.0\nX_test = X_test / 255.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T15:50:20.258649Z","iopub.execute_input":"2025-10-28T15:50:20.25924Z","iopub.status.idle":"2025-10-28T15:50:20.457789Z","shell.execute_reply.started":"2025-10-28T15:50:20.259216Z","shell.execute_reply":"2025-10-28T15:50:20.457197Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"X_train shape:\", np.shape(X_train))\nprint(\"y_train shape:\", np.shape(y_train))\nprint(\"X_test shape:\", np.shape(X_test))\nprint(\"y_test shape:\", np.shape(y_test))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T15:50:24.213382Z","iopub.execute_input":"2025-10-28T15:50:24.213644Z","iopub.status.idle":"2025-10-28T15:50:24.218417Z","shell.execute_reply.started":"2025-10-28T15:50:24.213624Z","shell.execute_reply":"2025-10-28T15:50:24.217692Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#CNN model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\nnum_classes = 5 \nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(60, 80, 3)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T15:50:27.872623Z","iopub.execute_input":"2025-10-28T15:50:27.873198Z","iopub.status.idle":"2025-10-28T15:50:29.325197Z","shell.execute_reply.started":"2025-10-28T15:50:27.873176Z","shell.execute_reply":"2025-10-28T15:50:29.324566Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#define Confusion Matrix Callback\nfrom tensorflow.keras.callbacks import Callback\nfrom sklearn.metrics import confusion_matrix\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nclass ConfusionMatrixLogger(Callback):\n    def __init__(self, X_val, y_val, label_names, interval=5):\n        super().__init__()\n        self.X_val = X_val\n        self.y_val = y_val\n        self.label_names = label_names\n        self.interval = interval\n\n    def on_epoch_end(self, epoch, logs=None):\n        if (epoch + 1) % self.interval == 0:\n            y_pred = self.model.predict(self.X_val)\n            y_pred_classes = np.argmax(y_pred, axis=1)\n            y_true = np.argmax(self.y_val, axis=1) if len(self.y_val.shape) > 1 else self.y_val\n\n            cm = confusion_matrix(y_true, y_pred_classes)\n            print(f\"\\nConfusion Matrix at Epoch {epoch+1}:\\n{cm}\")\n\n            # Optional: plot the matrix\n            plt.figure(figsize=(6, 5))\n            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                        xticklabels=self.label_names,\n                        yticklabels=self.label_names)\n            plt.xlabel('Predicted')\n            plt.ylabel('True')\n            plt.title(f'Confusion Matrix at Epoch {epoch+1}')\n            plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T16:10:53.104215Z","iopub.execute_input":"2025-10-28T16:10:53.10513Z","iopub.status.idle":"2025-10-28T16:10:53.111403Z","shell.execute_reply.started":"2025-10-28T16:10:53.105106Z","shell.execute_reply":"2025-10-28T16:10:53.110746Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nlabel_names = ['NEUTROPHIL', 'EOSINOPHIL', 'MONOCYTE', 'LYMPHOCYTE', 'OTHER']\ncallbacks = [\n    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n    ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n    ConfusionMatrixLogger(X_test, y_test, label_names, interval=5)  # your custom callback\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T16:12:25.746201Z","iopub.execute_input":"2025-10-28T16:12:25.74649Z","iopub.status.idle":"2025-10-28T16:12:25.751426Z","shell.execute_reply.started":"2025-10-28T16:12:25.746469Z","shell.execute_reply":"2025-10-28T16:12:25.750448Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nhistory = model.fit(X_train, y_train,\n                    validation_data=(X_test, y_test),\n                    epochs=50,\n                    batch_size=32,\n                    callbacks=callbacks)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T16:12:30.890584Z","iopub.execute_input":"2025-10-28T16:12:30.890857Z","iopub.status.idle":"2025-10-28T16:13:15.201395Z","shell.execute_reply.started":"2025-10-28T16:12:30.890837Z","shell.execute_reply":"2025-10-28T16:13:15.200768Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#view the loss and val-loss\nimport matplotlib.pyplot as plt\n\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Val Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T16:14:07.043317Z","iopub.execute_input":"2025-10-28T16:14:07.043904Z","iopub.status.idle":"2025-10-28T16:14:07.204937Z","shell.execute_reply.started":"2025-10-28T16:14:07.043883Z","shell.execute_reply":"2025-10-28T16:14:07.204097Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Model Loss Over Epochs')\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T16:14:13.198949Z","iopub.execute_input":"2025-10-28T16:14:13.199564Z","iopub.status.idle":"2025-10-28T16:14:13.370417Z","shell.execute_reply.started":"2025-10-28T16:14:13.199539Z","shell.execute_reply":"2025-10-28T16:14:13.369566Z"}},"outputs":[],"execution_count":null}]}